# System 2 Reasoning AI
**Experiments on deliberate, interpretable reasoning across neuro-symbolic models, symbolic regression, inference-time scaling, LLM agents, RL post-training in LLMs, and graph-based retrieval.**

---

## ðŸ§© Overview
This repository gathers six advanced projects exploring how modern AI systems can perform **SystemÂ 2â€“style reasoning** â€” deliberate, structured, and interpretable decisionâ€‘making that combines neural and symbolic approaches. Each notebook represents a distinct yet complementary direction toward **explainable, compositional, and multiâ€‘step reasoning**.

The work spans topics from **neuroâ€‘symbolic program induction** and **symbolic regression** to **inferenceâ€‘time reasoning optimization**, **reinforcement learning postâ€‘training for LLMs**, **visionâ€‘based LLM agents**, and **GraphRAGâ€‘style retrieval**.

---

## ðŸ“š Contents

| # | Project | Path | Description |
|---|--------|------|-------------|
| 1 | **Neuroâ€‘Symbolic Reasoning** | `neuro_symbolic_reasoning/neuro_symbolic_reasoning.ipynb` | CLEVR question answering via program induction, symbolic execution, and seq2seq models (LSTM + Transformer). |
| 2 | **Symbolic Regression** | `symbolic_regression/symbolic_regression.ipynb` | Equation discovery with Equation Learner (EQL) layers and a Transformer Seq2Seq model (token vocabulary â†’ SymPy expressions). |
| 3 | **Inferenceâ€‘Time Scaling** | `inference_time_scaling/inference_time_scaling.ipynb` | Compares Chainâ€‘ofâ€‘Thought, Bestâ€‘ofâ€‘N, Beam Search, Selfâ€‘Refine, Treeâ€‘ofâ€‘Thoughts, A*, and MCTS on math reasoning. |
| 4 | **RL Postâ€‘Training for LLMs** | `rl_post_training/rl_post_training.ipynb` | Twoâ€‘stage fineâ€‘tuning (SFT â†’ GRPO/TRL) with custom rewards for structure (`<think>â€¦</think>` & `<answer>â€¦</answer>`) and correctness. |
| 5 | **Vision LLM Agent** | `vision_llm_agent/vision_llm_agent.ipynb` | Multiâ€‘agent vision reasoning combining OpenCV heuristics with a VLM (Qwenâ€‘VL). Includes ablations and a small 100â€‘image dataset. |
| 6 | **GraphRAG Pipeline** | `graph_rag/graph_rag.ipynb` | Graphâ€‘based retrieval and community reasoning with entity extraction, Leiden community detection, and communityâ€‘scoped answering. |

---

## ðŸŽ¯ Core Themes
- **SystemÂ 2 Reasoning:** deliberate, multiâ€‘step problem solving  
- **Hybrid Neuroâ€‘Symbolic Learning:** combining neural inference with symbolic structure  
- **Reasoningâ€‘Time Optimization:** inferenceâ€‘time scaling, beam search, and ToT/MCTS exploration  
- **Reinforcement Learning Postâ€‘Training:** reward shaping for structured reasoning in LLMs  
- **LLM Agents & Vision Integration:** combining perception with reasoning chains  
- **Graphâ€‘Based Retrieval:** leveraging community structure for contextual memory  

---

## âš™ï¸ Repository Structure
```
System2-Reasoning-AI
â”‚   .gitignore
â”‚   LICENSE
â”‚   README.md
â”‚
â”œâ”€â”€ graph_rag
â”‚   â””â”€â”€ graph_rag.ipynb
â”‚
â”œâ”€â”€ inference_time_scaling
â”‚   â””â”€â”€ inference_time_scaling.ipynb
â”‚
â”œâ”€â”€ neuro_symbolic_reasoning
â”‚   â”‚   neuro_symbolic_reasoning.ipynb
â”‚   â”‚   prompt_example.txt
â”‚   â”‚
â”‚   â”œâ”€â”€ dataH5Files
â”‚   â”‚   â””â”€â”€ (dataset files)
â”‚   â”‚
â”‚   â””â”€â”€ utils
â”‚       â”œâ”€â”€ clevr_executor.py
â”‚       â”œâ”€â”€ logger.py
â”‚       â”œâ”€â”€ preprocess.py
â”‚       â”œâ”€â”€ preprocess_questions.py
â”‚       â”œâ”€â”€ programs.py
â”‚       â”œâ”€â”€ utils.py
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ rl_post_training
â”‚   â””â”€â”€ rl_post_training.ipynb
â”‚
â”œâ”€â”€ symbolic_regression
â”‚   â”œâ”€â”€ dataset.csv
â”‚   â””â”€â”€ symbolic_regression.ipynb
â”‚
â””â”€â”€ vision_llm_agent
    â”‚   vision_llm_agent.ipynb
    â”‚
    â””â”€â”€ agent_data
        â”‚   data.csv
        â”‚
        â””â”€â”€ images
            â”œâ”€â”€ 1018.png
            â”œâ”€â”€ 10461.png
            â”œâ”€â”€ 10546.png
            â”œâ”€â”€ 10916.png
            â”œâ”€â”€ 11286.png
            â”œâ”€â”€ ...
            â””â”€â”€ 9588.png

```

Each folder contains an independent Jupyter notebook and (where applicable) the supporting data included in your upload.

---

## Environment Setup
> These notebooks target PythonÂ 3.10+. Install only what you need for the notebook you plan to run.

```bash
pip install torch transformers accelerate datasets tqdm numpy matplotlib pandas sympy scikit-learn             trl peft vllm opencv-python pillow             langchain langchain-community langchain-graphrag networkx cdlib pypdf
```
**Notes**
- Some parts (e.g., RL postâ€‘training and GraphRAG community detection) benefit from a **GPU** runtime.  
- If using verifier or external API calls in the inferenceâ€‘time scaling notebook, configure your **API keys via environment variables** instead of hardâ€‘coding.

---

## ðŸ“Š Selected Observations
- **Vision LLM Agent:** In the provided ablations, the best deepâ€‘agent configuration (AgentÂ 1 + AgentÂ 3) outperformed zeroâ€‘shot and classic pipelines on the 100â€‘image set.  
- **Inferenceâ€‘Time Scaling:** Searchâ€‘based and verificationâ€‘based strategies (e.g., Bestâ€‘ofâ€‘N, ToT/MCTS) showed higher accuracy than plain CoT at additional compute cost.  
- **RL Postâ€‘Training for LLMs:** GRPO with structured rewards improved format compliance and answer correctness relative to SFTâ€‘only baselines.  
- **GraphRAG:** Community summaries derived from the entityâ€‘relation graph improved longâ€‘document question answering quality relative to naive chunk retrieval.

*(Exact metrics depend on runtime settings and hardware; see notebook outputs for details.)*

---

## Motivation
SystemÂ 1 reasoning in LLMs is fast but often shallow. This project explores **SystemÂ 2 reasoning** â€” deliberate, symbolic, and interpretable â€” by experimenting with architectures and training strategies that encourage models to reason, plan, and reflect.

---

## Citation
If you use this repository in your research, please cite it as follows:

```bibtex
@misc{System2-Reasoning-AI,
  author       = {[Radin Cheraghi/SUT]},
  title        = {Experiments on System 2 reasoning},
  year         = {2025},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{https://github.com/radinch/System2-Reasoning-AI.git}}
}